# Model arguments
model_name_or_path: src/SFT_model
model_revision: main
torch_dtype: bfloat16
attn_implementation: flash_attention_2


dataset_name: defined_in_source_code
system_prompt: "You are a Schema linking assistant. Your task is to select appropriate table names and corresponding column names from the database in <database>...</database> based on the user's question in <question>...</question>. 
Follow this response template: <think>\nYour Thought Process (Why were these choices made?)\n</think>\n<answer>\n###Tables: (Related Table);\n###Columns: (Related Columns from Tables);\n</answer>"
dataset_prompt_column: problem



# GRPO trainer config
bf16: true
use_vllm: true
do_eval: false
eval_steps: 800
gradient_accumulation_steps: 120
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false
learning_rate: 2.0e-05
log_completions: true
log_level: info
logging_first_step: true
logging_steps: 2
logging_strategy: steps
lr_scheduler_type: cosine
max_prompt_length: 2400
max_completion_length: 2048
max_steps: -1
num_generations:  10
num_train_epochs: 2
output_dir: data/GRPO-schema-fix
overwrite_output_dir: true
per_device_eval_batch_size: 8
per_device_train_batch_size: 10
reward_funcs:
- accuracy
- format
- tag_count
- length
reward_weights:
- 0.5
- 0.5
- 0.5
- 1.0
save_strategy: "steps"
save_total_limit: 2
seed: 8
warmup_ratio: 0.1
save_steps: 10
temperature: 1.0