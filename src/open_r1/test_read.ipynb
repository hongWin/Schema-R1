{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1af9636",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df36f203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_dataset  焊死\n",
    "model_path = \"../SFT_model\"\n",
    "file_path = \"../GRPO_data/training_prompt2.csv\"  \n",
    "df = pd.read_csv(file_path).iloc[200:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2969c8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c2ba237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a Schema linking assistant. Your task is to select appropriate table names and corresponding column names from the database in <database>...</database> based on the user's question in <question>...</question>. \n",
      "Follow this response template: <think>\n",
      "Your Thought Process (Why were these choices made?)\n",
      "</think>\n",
      "<answer>\n",
      "###Tables: (Related Table);\n",
      "###Columns: (Related Columns from Tables);\n",
      "</answer> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a Schema linking assistant. Your task is to select appropriate table names and corresponding column names from the database in <database>...</database> based on the user's question in <question>...</question>. \n",
    "Follow this response template: <think>\\nYour Thought Process (Why were these choices made?)\\n</think>\\n<answer>\\n###Tables: (Related Table);\\n###Columns: (Related Columns from Tables);\\n</answer> \n",
    "\"\"\"\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24c05dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5645a34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(question, database_schema):\n",
    "    conversation = []\n",
    "    conversation0 = {}\n",
    "    conversation1 = {}\n",
    "    conversation0[\"role\"] = \"system\"\n",
    "    conversation0[\"content\"] = system_prompt\n",
    "    conversation1[\"role\"] = \"user\"\n",
    "    conversation1[\"content\"] = f\"<question>{question}</question>\\n<database>{database_schema}</database>\" + \"\\n\"\n",
    "    conversation.append(conversation0)\n",
    "    conversation.append(conversation1)\n",
    "    all_info = system_prompt + f\"<question>{question}</question>\\n<database>{database_schema}</database>\" + \"\\n\"\n",
    "#     print(conversation2[\"content\"])\n",
    "    return conversation, all_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4fc672ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_data = {}\n",
    "prompts = []\n",
    "solutions = []\n",
    "max_token = 0\n",
    "for index, row in df.iterrows():\n",
    "    prompt, all_info = make_prompt(row[\"question\"],row[\"database_schema\"])\n",
    "    prompts.append(prompt)\n",
    "    solutions.append(row[\"target_schema\"])\n",
    "    token_len = len(tokenizer(all_info, add_special_tokens=False)[\"input_ids\"])\n",
    "    if  token_len >  max_token:\n",
    "        max_token = token_len\n",
    "trans_data[\"prompt\"] = prompts\n",
    "trans_data[\"solution\"] = solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d58826e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2143\n"
     ]
    }
   ],
   "source": [
    "print(max_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f9dc748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt': [{'content': \"\\nYou are a Schema linking assistant. Your task is to select appropriate table names and corresponding column names from the database in <database>...</database> based on the user's question in <question>...</question>. \\nFollow this response template: <think>\\nYour Thought Process (Why were these choices made?)\\n</think>\\n<answer>\\n###Tables: (Related Table);\\n###Columns: (Related Columns from Tables);\\n</answer> \\n\", 'role': 'system'}, {'content': '<question>What are the names of people in ascending order of weight?</question>\\n<database>CREATE TABLE `entrepreneur` (\\n  Entrepreneur_ID INT PRIMARY KEY,\\n  People_ID INT REFERENCES people(People_ID),\\n  Company TEXT,\\n  Money_Requested REAL,\\n  Investor TEXT\\n);\\n\\nCREATE TABLE `people` (\\n  People_ID INT PRIMARY KEY,\\n  Name TEXT,\\n  Height REAL,\\n  Weight REAL,\\n  Date_of_Birth TEXT\\n);\\n\\n</database>\\n', 'role': 'user'}], 'solution': '###Tables: people;\\n###Columns: people.name, people.weight;\\n'}\n"
     ]
    }
   ],
   "source": [
    "trans_data = pd.DataFrame(trans_data)\n",
    "trans_data = Dataset.from_pandas(trans_data,split=\"train\")\n",
    "for sample in trans_data:\n",
    "    print(sample)\n",
    "    break  # 仅打印第一个样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d54255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openr1",
   "language": "python",
   "name": "openr1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
